# ğŸ”§ RUNBOOK_TROUBLESHOOTING.md - Troubleshooting DataLake

**Data de CriaÃ§Ã£o:** 9 de dezembro de 2025
**VersÃ£o:** 1.0
**ResponsÃ¡vel:** DataLake Operations Team

---

## ğŸ“‹ VisÃ£o Geral

Este runbook contÃ©m procedimentos de diagnÃ³stico e resoluÃ§Ã£o para os problemas mais comuns no DataLake Iceberg.

**Tempo Estimado:** 5-30 minutos por problema
**Ferramentas NecessÃ¡rias:** SSH, acesso root, ferramentas de monitoramento

---

## ğŸš¨ Problemas CrÃ­ticos (P0)

### 1. Sistema IndisponÃ­vel - DataLake Completo Down

**Sintomas:**
- Spark Master nÃ£o responde (porta 8080)
- MinIO nÃ£o acessÃ­vel (porta 9000)
- Hive Metastore falha
- AplicaÃ§Ãµes nÃ£o conseguem processar dados

**DiagnÃ³stico RÃ¡pido:**
```bash
# Verificar serviÃ§os crÃ­ticos
systemctl status mariadb minio kafka spark-master --no-pager

# Verificar recursos sistema
df -h / && free -h && uptime

# Verificar rede
ping -c 3 8.8.8.8
```

**AÃ§Ãµes Imediatas:**
1. **Reiniciar serviÃ§os na ordem correta** (ver RUNBOOK_STARTUP.md)
2. **Verificar logs de sistema:** `journalctl --since "1 hour ago"`
3. **Escalar se indisponÃ­vel > 15 min**

---

### 2. Perda de Dados - CorrupÃ§Ã£o Iceberg

**Sintomas:**
- Queries falham com "table not found"
- Arquivos Parquet corrompidos
- Metadados inconsistentes

**DiagnÃ³stico:**
```bash
# Verificar estrutura Iceberg
hdfs dfs -ls s3a://datalake/warehouse/

# Validar metadados
beeline -u "jdbc:hive2://localhost:10000" -e "SHOW TABLES IN default;"

# Verificar integridade arquivos
spark-submit --class org.apache.spark.sql.CheckIcebergIntegrity \
  --master spark://localhost:7077 \
  /path/to/iceberg-integrity-check.jar
```

**RecuperaÃ§Ã£o:**
1. **Restaurar do backup** (ver RUNBOOK_BACKUP_RESTORE.md)
2. **Recriar tabela se backup indisponÃ­vel**
3. **Validar integridade pÃ³s-recuperaÃ§Ã£o**

---

## âš ï¸ Problemas Graves (P1)

### 3. Performance Degradada - Queries Lentas

**Sintomas:**
- Queries demoram > 30s (baseline: < 5s)
- CPU/MemÃ³ria alta
- Spark executors falhando

**DiagnÃ³stico:**
```bash
# Verificar recursos Spark
curl http://localhost:8080/json/ | jq '.workers[] | {host, coresused, memoryused}'

# Analisar query plan
spark.sql("EXPLAIN EXTENDED SELECT * FROM table WHERE condition").show()

# Verificar estatÃ­sticas tabela
spark.sql("DESCRIBE EXTENDED table_name").show()
```

**OtimizaÃ§Ã£o:**
```sql
-- Atualizar estatÃ­sticas
ANALYZE TABLE table_name COMPUTE STATISTICS;

-- Otimizar layout
OPTIMIZE table_name;

-- Verificar CBO
SET spark.sql.cbo.enabled=true;
```

### 4. Conectividade S3 Perdida

**Sintomas:**
- Erro: "SignatureDoesNotMatch"
- Timeout em operaÃ§Ãµes S3
- MinIO logs mostram falhas de autenticaÃ§Ã£o

**DiagnÃ³stico:**
```bash
# Testar conectividade MinIO
curl -I http://localhost:9000/minio/health/live

# Verificar credenciais
mc alias set test http://localhost:9000 datalake iRB;g2&ChZ&XQEW!
mc ls test/

# Logs MinIO
tail -f /opt/minio/logs/minio.log
```

**ResoluÃ§Ã£o:**
1. **Verificar core-site.xml:**
   ```xml
   <property>
     <name>fs.s3a.access.key</name>
     <value>datalake</value>
   </property>
   <property>
     <name>fs.s3a.secret.key</name>
     <value>iRB;g2&amp;ChZ&amp;XQEW!</value>
   </property>
   ```
2. **Reiniciar Spark:** `/opt/spark/sbin/stop-master.sh && /opt/spark/sbin/start-master.sh`
3. **Testar conectividade**

---

## ğŸ”§ Problemas Moderados (P2)

### 5. Kafka Lag Alto

**Sintomas:**
- Consumer lag > 10000 mensagens
- CDC pipeline atrasado
- Alertas de latÃªncia

**DiagnÃ³stico:**
```bash
# Verificar lag
/opt/kafka/bin/kafka-consumer-groups.sh \
  --bootstrap-server localhost:9092 \
  --group cdc_consumer \
  --describe

# Verificar throughput
/opt/kafka/bin/kafka-run-class.sh kafka.tools.ProducerPerformance \
  --topic test --num-records 1000 --record-size 100 \
  --throughput -1 --producer-props bootstrap.servers=localhost:9092
```

**AÃ§Ãµes:**
1. **Aumentar particionamento** no Spark
2. **Otimizar consumer config:**
   ```properties
   max.poll.records=500
   fetch.min.bytes=1024
   fetch.max.wait.ms=500
   ```
3. **Monitorar e ajustar**

### 6. MemÃ³ria Spark Insuficiente

**Sintomas:**
- OutOfMemoryError
- Executors falhando
- GC overhead alto

**DiagnÃ³stico:**
```bash
# Verificar configuraÃ§Ã£o atual
grep -r "spark.executor.memory" /opt/spark/conf/

# Monitorar GC
jstat -gcutil $(jps | grep Master | awk '{print $1}') 1000 5
```

**Ajustes:**
```bash
# spark-defaults.conf
spark.executor.memory=4g
spark.executor.memoryOverhead=1g
spark.memory.fraction=0.8
spark.memory.storageFraction=0.3
```

---

## ğŸ“Š Monitoramento ContÃ­nuo

### MÃ©tricas CrÃ­ticas
```bash
# Dashboard rÃ¡pido
watch -n 5 '
echo "=== SPARK ==="
curl -s http://localhost:8080/json/ | jq ".activeApps | length"
echo "=== KAFKA ==="
/opt/kafka/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group cdc_consumer --describe | grep -E "LAG|CURRENT" | tail -5
echo "=== MINIO ==="
mc ls datalake/ | wc -l
'
```

### Logs Essenciais
- **Spark:** `/opt/spark/logs/`
- **Kafka:** `/opt/kafka/logs/`
- **MinIO:** `/opt/minio/logs/`
- **Hive:** `/opt/hive/logs/`
- **Sistema:** `journalctl -u [service]`

---

## ğŸ¯ Decision Tree de Troubleshooting

```
Problema reportado?
â”œâ”€â”€ SIM â†’ Verificar sintomas em alertas
â”‚   â”œâ”€â”€ P0 (Sistema down) â†’ RUNBOOK_STARTUP + Escalar
â”‚   â”œâ”€â”€ P1 (Performance) â†’ DiagnÃ³stico Spark/Kafka
â”‚   â””â”€â”€ P2 (Funcional) â†’ Logs especÃ­ficos
â””â”€â”€ NÃƒO â†’ Monitoramento proativo
    â”œâ”€â”€ MÃ©tricas baseline OK? â†’ Continuar monitoramento
    â””â”€â”€ Anomalia detectada â†’ Investigar logs
```

---

## ğŸ“ Escalation Matrix

| Severidade | Tempo para ResoluÃ§Ã£o | Escalation |
|------------|---------------------|------------|
| **P0** | 15 min | Imediato para Lead + Gerente |
| **P1** | 1 hora | Lead tÃ©cnico |
| **P2** | 4 horas | Time de operaÃ§Ãµes |
| **P3** | 24 horas | PrÃ³ximo dia Ãºtil |

---

## ğŸ“ Registro de Incidentes

| Data/Hora | Problema | Severidade | ResoluÃ§Ã£o | Tempo | ResponsÃ¡vel |
|-----------|----------|------------|-----------|-------|-------------|
| 2025-12-09 16:00 | S3 Auth Fail | P1 | Credenciais corrigidas | 10 min | [Nome] |
| | | | | | |
| | | | | | |
| | | | | | |

---

*Ãšltima atualizaÃ§Ã£o: 9 de dezembro de 2025*</content>
<parameter name="filePath">c:\Users\Gabriel Santana\Documents\VS_Code\DataLake_FB-v2\etc\runbooks\RUNBOOK_TROUBLESHOOTING.md