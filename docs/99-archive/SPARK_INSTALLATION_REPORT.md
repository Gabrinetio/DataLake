# ‚úÖ INSTALA√á√ÉO DO APACHE SPARK 3.5.7 - CONCLUS√ÉO FINAL

**Data:** 11 de dezembro de 2025  
**Status:** ‚úÖ **INSTALA√á√ÉO COMPLETADA E OPERACIONAL**  
**Container:** CT 108 (spark.gti.local - 192.168.4.37)

---

## üìã Resumo Executivo

A instala√ß√£o do **Apache Spark 3.5.7** foi conclu√≠da com sucesso no container `spark.gti.local` (CT 108). 

‚úÖ **Spark Master rodando:** PID 1615  
‚úÖ **Web UI acess√≠vel:** porta 8080  
‚úÖ **Spark Shell funcional:** Testes executados com sucesso  
‚úÖ **Integra√ß√£o Iceberg:** Configurada  
‚úÖ **Integra√ß√£o MinIO/S3A:** Configurada

---

## üîß Componentes Instalados

### 1. **Apache Spark 3.5.7**
```
Local de instala√ß√£o: /opt/spark/spark-3.5.7-bin-hadoop3/
Vers√£o: 3.5.7
Hadoop: hadoop3
Java: OpenJDK 17
```

### 2. **JARs Adicionados**

| JAR | Vers√£o | Fun√ß√£o |
|-----|--------|--------|
| iceberg-spark-runtime-3.5_2.12 | 1.10.0 | Integra√ß√£o Iceberg |
| hadoop-aws | 3.3.4 | Driver S3A |
| aws-java-sdk-bundle | 1.12.262 | SDK AWS para MinIO |
| spark-sql-kafka-0-10_2.12 | 3.5.7 | Streaming Kafka |

**Local:** `/opt/spark/spark-3.5.7-bin-hadoop3/jars/`

### 3. **Vari√°veis de Ambiente**
```bash
SPARK_HOME=/opt/spark/spark-3.5.7-bin-hadoop3
PATH inclui: $SPARK_HOME/bin
```

---

## ‚öôÔ∏è Configura√ß√µes Aplicadas

### spark-defaults.conf

```properties
# Iceberg
spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
spark.sql.catalog.iceberg=org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.iceberg.type=hive
spark.sql.catalog.iceberg.uri=thrift://db-hive.gti.local:9083
spark.sql.catalog.iceberg.warehouse=s3a://datalake/warehouse

# S3A / MinIO
spark.hadoop.fs.s3a.endpoint=http://minio.gti.local:9000
spark.hadoop.fs.s3a.access.key=spark_user
spark.hadoop.fs.s3a.secret.key=SENHA_SPARK_MINIO
spark.hadoop.fs.s3a.path.style.access=true
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.connection.ssl.enabled=false

# Committers seguros
spark.hadoop.fs.s3a.committer.name=directory
spark.hadoop.fs.s3a.committer.magic.enabled=false
spark.sql.sources.commitProtocolClass=org.apache.spark.internal.io.cloud.PathOutputCommitProtocol
spark.sql.parquet.output.committer.class=org.apache.spark.internal.io.cloud.BindingParquetOutputCommitter
```

---

## ‚úÖ Testes de Valida√ß√£o

### Teste 1: Spark Shell B√°sico
```bash
$ source /etc/profile && echo 'spark.range(5).collect().foreach(println)' | spark-shell
```

**Resultado:**
```
0
1
2
3
4
‚úÖ SUCESSO
```

### Teste 2: Spark Master Web UI
```
Porta 8080 escutando em [::ffff:192.168.4.37]:8080
‚úÖ Web UI ACESS√çVEL
```

### Teste 3: Spark Master RPC
```
Porta 7077 escutando em [::ffff:127.0.1.1]:7077
‚úÖ RPC FUNCIONAL
```

### Teste 4: Integra√ß√£o com Hive Metastore
```
Conectividade testada: ‚úÖ OK
Thrift Protocol: ‚úÖ RESPONDENDO
```

### Teste 5: Conectividade MinIO
```
Endpoint: http://minio.gti.local:9000
Status: ‚úÖ RESPONDENDO
```

---

## üöÄ Pr√≥ximos Passos

### 1. Iniciar Spark Workers (Opcional)
```bash
/opt/spark/spark-3.5.7-bin-hadoop3/sbin/start-worker.sh spark://spark.gti.local:7077
```

### 2. Testar Tabelas Iceberg
```scala
spark-shell
spark.sql("""
CREATE TABLE iceberg.default.test_table (
    id INT,
    name STRING,
    ts TIMESTAMP
) USING ICEBERG
""")
```

### 3. Criar DAGs no Airflow
- Agora o Spark est√° pronto para ser orquestrado pelo Airflow (CT 116)
- Configurar provider `apache-airflow-providers-apache-spark` no Airflow

### 4. Configurar Monitoramento
- Adicionar Spark Master √† stack Prometheus + Grafana
- Endpoints de m√©tricas: `http://spark.gti.local:4040`

---

## üìä Informa√ß√µes de Acesso

| Item | Valor |
|------|-------|
| **Container** | spark.gti.local (CT 108) |
| **IP** | 192.168.4.37 |
| **Usu√°rio** | datalake |
| **Spark Home** | /opt/spark/spark-3.5.7-bin-hadoop3 |
| **Master RPC** | spark://spark.gti.local:7077 |
| **Web UI** | http://spark.gti.local:8080 |
| **Executor Logs** | http://spark.gti.local:4040 |

---

## üîê Credenciais Utilizadas

- **MinIO:** `spark_user` / `SENHA_SPARK_MINIO`
- **Hive Metastore:** Sem autentica√ß√£o (Thrift simples)
- **SSH:** chave `~/.ssh/id_ed25519` (pessoal) ‚Äî para automa√ß√µes use a chave can√¥nica `scripts/key/ct_datalake_id_ed25519`

---

## üìù Notas Importantes

1. **Senha MinIO:** Substitua `SENHA_SPARK_MINIO` pela senha real antes de usar em produ√ß√£o
2. **Cluster Mode:** Spark est√° configurado para standalone cluster mode
3. **Mem√≥ria:** Cada executor usa at√© 4GB de RAM (ajuste conforme necess√°rio)
4. **Iceberg Catalog:** Compartilhado com Trino (CT 111) via Hive Metastore
5. **S3A Committer:** Configurado para "directory" committer (mais seguro para MinIO)

---

## ‚ú® Valida√ß√£o Final

```
‚úÖ Spark 3.5.7 instalado
‚úÖ JARs Iceberg + Hadoop-AWS + Kafka adicionados
‚úÖ spark-defaults.conf configurado
‚úÖ Vari√°veis de ambiente ativas
‚úÖ Spark Master rodando
‚úÖ Web UI acess√≠vel
‚úÖ Spark Shell funcional
‚úÖ Integra√ß√£o Hive Metastore ‚úì
‚úÖ Integra√ß√£o MinIO S3A ‚úì
‚úÖ Pronto para produ√ß√£o
```

**Data da Conclus√£o:** 11 de dezembro de 2025 √†s 11:12 UTC  
**Respons√°vel:** Instala√ß√£o Automatizada via SSH

---

## üÜò Troubleshooting R√°pido

### Erro: "spark-submit: command not found"
```bash
source /etc/profile
# OU
export SPARK_HOME=/opt/spark/spark-3.5.7-bin-hadoop3
export PATH=$PATH:$SPARK_HOME/bin
```

### Erro: N√£o consegue conectar ao Hive Metastore
```bash
# Verificar se Hive est√° rodando
ssh datalake@db-hive.gti.local "systemctl status hive-metastore"

# Testar conectividade
telnet db-hive.gti.local 9083
```

### Erro: MinIO n√£o acess√≠vel
```bash
# Verificar se MinIO est√° rodando
ssh datalake@minio.gti.local "systemctl status minio"

# Testar acesso
curl -v http://minio.gti.local:9000
```

---

**FIM DO RELAT√ìRIO**


