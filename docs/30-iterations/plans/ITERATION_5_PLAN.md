# ğŸš€ ITERATION 5: Change Data Capture + Row-Level Access Control + BI Integration

**Data:** 7 de dezembro de 2025  
**Status:** Planejada â³  
**Estimativa:** ~2 horas  
**Meta:** 90% projeto completo  

---

## ğŸ“‹ Resumo Executivo

IteraÃ§Ã£o 5 implementa trÃªs funcionalidades crÃ­ticas para DataLake em produÃ§Ã£o:

1. **CDC (Change Data Capture)** - Capturar mudanÃ§as incrementais
2. **RLAC (Row-Level Access Control)** - Controle granular de acesso
3. **BI Integration** - IntegraÃ§Ã£o com ferramentas de BI (Superset/Tableau)

**Resultado esperado:** Sistema completo, pronto para produÃ§Ã£o, com 90% de cobertura.

---

## âœ… PrÃ©-requisitos

- âœ… IteraÃ§Ã£o 1: Data generation e benchmark (50K records)
- âœ… IteraÃ§Ã£o 2: Time travel e MERGE INTO (snapshots funcionais)
- âœ… IteraÃ§Ã£o 3: Compaction e monitoring (0.703s avg queries)
- âœ… IteraÃ§Ã£o 4: Backup/restore, DR, security (23 polÃ­ticas)
- âœ… Server 192.168.4.33 acessÃ­vel
- âœ… Spark 4.0.1 funcionando
- âœ… Data em `/home/datalake/data/vendas_small`

---

## ğŸ¯ Objetivos EspecÃ­ficos

### 1ï¸âƒ£ CDC (Change Data Capture)

**O que Ã©:** Capturar e replicar apenas as mudanÃ§as de dados, nÃ£o todo dataset

**Por que Ã© importante:**
- Reduz transferÃªncia de dados (apenas deltas)
- Permite replicaÃ§Ã£o em tempo real
- Base para data pipelines incremental

**ImplementaÃ§Ã£o:**

```
FASE 1: Setup
â”œâ”€ Criar tabela "vendas_live" com dados iniciais
â”œâ”€ Habilitar CDC via Iceberg snapshot tracking
â””â”€ Configurar diretÃ³rio de staging

FASE 2: Captura de MudanÃ§as
â”œâ”€ INSERT: +10 novos registros
â”œâ”€ UPDATE: Modificar 5 registros existentes
â”œâ”€ DELETE: Remover 3 registros (soft delete)
â””â”€ Capturar delta entre snapshots

FASE 3: ValidaÃ§Ã£o
â”œâ”€ Verificar CDC latency < 5 minutos
â”œâ”€ Comparar delta calculado vs. real
â”œâ”€ Teste de replicaÃ§Ã£o em tabela espelho
â””â”€ Performance baseline
```

**Script:** `test_cdc_pipeline.py`  
**ValidaÃ§Ã£o:** Delta capture correctness, latency < 5 min

---

### 2ï¸âƒ£ RLAC (Row-Level Access Control)

**O que Ã©:** Controle de acesso no nÃ­vel de linhas (nÃ£o apenas tabelas)

**Exemplo:**
```sql
-- User A vÃª apenas vendas do departamento X
SELECT * FROM vendas 
WHERE department = get_user_department();

-- User B vÃª apenas vendas do mÃªs atual
SELECT * FROM vendas 
WHERE DATE_TRUNC('month', data_venda) = CURRENT_DATE();
```

**ImplementaÃ§Ã£o:**

```
FASE 1: Setup
â”œâ”€ Criar coluna "department" em tabela vendas
â”œâ”€ Criar coluna "user_id" para auditoria
â”œâ”€ Popula dados de teste por departamento
â””â”€ Criar funÃ§Ã£o SQL get_user_dept()

FASE 2: RLAC Logic
â”œâ”€ Implementar view com filtro automÃ¡tico
â”œâ”€ Testar acesso de User A (dept=Sales)
â”œâ”€ Testar acesso de User B (dept=Finance)
â”œâ”€ Verificar User C sem acesso explÃ­cito

FASE 3: Performance Impact
â”œâ”€ Query SEM filtro RLAC: baseline
â”œâ”€ Query COM filtro RLAC: compare
â”œâ”€ Objetivo: < 5% overhead
â””â”€ PartiÃ§Ã£o ajuda performance
```

**Script:** `test_rlac_implementation.py`  
**ValidaÃ§Ã£o:** Access control enforced, < 5% performance impact

---

### 3ï¸âƒ£ BI Integration

**O que Ã©:** Conectar DataLake com ferramentas de BI (Superset, Tableau, Power BI)

**Ferramentas suportadas:**
- Apache Superset (open source, jÃ¡ em container)
- Tableau (if available)
- Power BI (if available)
- Metabase (alternative)

**ImplementaÃ§Ã£o:**

```
FASE 1: Superset Setup
â”œâ”€ Verificar Superset acessÃ­vel (localhost:8088)
â”œâ”€ Conectar banco de dados Spark/Iceberg
â”œâ”€ Criar data source para tabela vendas
â””â”€ Test basic connectivity

FASE 2: Dashboard Creation
â”œâ”€ Criar dashboard "Sales Overview"
â”œâ”€ Adicionar chart: Total sales by month
â”œâ”€ Adicionar chart: Top departments
â”œâ”€ Adicionar chart: Performance metrics
â””â”€ Test interactivity

FASE 3: Query Performance
â”œâ”€ Executar queries via Superset
â”œâ”€ Medir tempo de resposta (target < 30s)
â”œâ”€ Benchmark vs. direct SQL
â””â”€ Optimize slow queries
```

**Script:** `test_bi_integration.py`  
**ValidaÃ§Ã£o:** Dashboard functional, queries < 30s

---

## ğŸ“ Arquivos a Criar

### Scripts Python (em `src/tests/`)

```python
# 1. CDC Pipeline
test_cdc_pipeline.py
â”œâ”€ Phase 1: Setup tabela "vendas_live"
â”œâ”€ Phase 2: Aplicar mudanÃ§as (INSERT/UPDATE/DELETE)
â”œâ”€ Phase 3: Capturar deltas entre snapshots
â””â”€ Resultado: CDC_latency < 5 min, correctness 100%

# 2. RLAC Implementation
test_rlac_implementation.py
â”œâ”€ Phase 1: Setup departamentos e usuÃ¡rios
â”œâ”€ Phase 2: Implementar views com RLAC
â”œâ”€ Phase 3: Testar acesso para cada user
â””â”€ Resultado: Acesso controlado, overhead < 5%

# 3. BI Integration
test_bi_integration.py
â”œâ”€ Phase 1: Conectar ao Superset
â”œâ”€ Phase 2: Criar data source
â”œâ”€ Phase 3: Executar queries de teste
â””â”€ Resultado: Dashboard funcional, queries < 30s
```

### DocumentaÃ§Ã£o (em `docs/`)

```markdown
results/ITERATION_5_RESULTS.md
â”œâ”€ Resumo de cada feature
â”œâ”€ MÃ©tricas de sucesso
â”œâ”€ LiÃ§Ãµes aprendidas
â””â”€ RecomendaÃ§Ãµes produÃ§Ã£o

CDC_IMPLEMENTATION.md
â”œâ”€ Teoria: Como funciona CDC
â”œâ”€ ImplementaÃ§Ã£o: CÃ³digo Spark
â”œâ”€ Performance: OtimizaÃ§Ãµes
â””â”€ Troubleshooting: Problemas comuns

RLAC_IMPLEMENTATION.md
â”œâ”€ Teoria: Row-level security
â”œâ”€ ImplementaÃ§Ã£o: SQL views + Spark
â”œâ”€ Testing: Casos de uso
â””â”€ Production: Deployment checklist

BI_INTEGRATION_GUIDE.md
â”œâ”€ Setup Superset
â”œâ”€ Criar data sources
â”œâ”€ Build dashboards
â””â”€ Performance tuning
```

---

## ğŸ” CritÃ©rios de Sucesso

| Feature | CritÃ©rio | Target |
|---------|----------|--------|
| **CDC** | Latency | < 5 min |
| **CDC** | Correctness | 100% |
| **CDC** | Data loss | 0 |
| **RLAC** | Enforcement | 100% |
| **RLAC** | Overhead | < 5% |
| **RLAC** | Access control | Granular |
| **BI** | Query time | < 30s |
| **BI** | Dashboard latency | < 2s |
| **BI** | Connectivity | 100% uptime |

---

## ğŸ“Š Estrutura de Teste

### CDC Pipeline Test
```python
class CDCPipelineTest:
    def setup(self):
        # Criar tabela vendas_live com 50K records
        
    def phase1_initial_snapshot(self):
        # Snapshot 1: baseline
        
    def phase2_apply_changes(self):
        # INSERT 10 novos
        # UPDATE 5 existentes
        # DELETE 3 (soft delete)
        # Snapshot 2: apÃ³s mudanÃ§as
        
    def phase3_capture_delta(self):
        # Comparar snapshots
        # Extrair INSERTs, UPDATEs, DELETEs
        # Validar contagem
        
    def validate(self):
        # Assert: delta correctness
        # Assert: latency < 5 min
        # Assert: no data loss
        
    def performance_metrics(self):
        # CDC overhead %
        # Latency measurements
        # Throughput (records/sec)
```

### RLAC Implementation Test
```python
class RLACImplementationTest:
    def setup(self):
        # Criar departamentos
        # Criar usuÃ¡rios
        # Criar views com filtros
        
    def test_user_a_sees_only_sales_dept(self):
        # User A (Sales) queries
        # Assert: only Sales data
        
    def test_user_b_sees_only_finance_dept(self):
        # User B (Finance) queries
        # Assert: only Finance data
        
    def test_user_c_no_access(self):
        # User C without explicit access
        # Assert: access denied or empty
        
    def performance_impact(self):
        # Query sem RLAC: T1
        # Query com RLAC: T2
        # Assert: (T2-T1)/T1 < 5%
```

### BI Integration Test
```python
class BIIntegrationTest:
    def setup(self):
        # Conectar ao Superset
        # Criar data source
        
    def test_superset_connectivity(self):
        # Assert: connection successful
        # Assert: table accessible
        
    def test_dashboard_creation(self):
        # Create dashboard
        # Add charts
        # Assert: dashboard created
        
    def test_query_performance(self):
        # Execute sample queries
        # Measure latency
        # Assert: queries < 30s
```

---

## ğŸ”— Fluxo de ImplementaÃ§Ã£o

```
START
â”‚
â”œâ”€ 1. CDC Pipeline
â”‚   â”œâ”€ Create test_cdc_pipeline.py
â”‚   â”œâ”€ Phase 1: Setup tabela
â”‚   â”œâ”€ Phase 2: Apply changes
â”‚   â”œâ”€ Phase 3: Capture delta
â”‚   â””â”€ Validate results
â”‚
â”œâ”€ 2. RLAC Implementation
â”‚   â”œâ”€ Create test_rlac_implementation.py
â”‚   â”œâ”€ Phase 1: Setup users/depts
â”‚   â”œâ”€ Phase 2: Create RLAC views
â”‚   â”œâ”€ Phase 3: Test access control
â”‚   â””â”€ Validate performance < 5%
â”‚
â”œâ”€ 3. BI Integration
â”‚   â”œâ”€ Create test_bi_integration.py
â”‚   â”œâ”€ Phase 1: Connect Superset
â”‚   â”œâ”€ Phase 2: Create dashboard
â”‚   â”œâ”€ Phase 3: Test queries
â”‚   â””â”€ Validate < 30s latency
â”‚
â”œâ”€ 4. Documentation
â”‚   â”œâ”€ Create results/ITERATION_5_RESULTS.md
â”‚   â”œâ”€ Create CDC_IMPLEMENTATION.md
â”‚   â”œâ”€ Create RLAC_IMPLEMENTATION.md
â”‚   â”œâ”€ Create BI_INTEGRATION_GUIDE.md
â”‚   â””â”€ Update docs/INDICE_DOCUMENTACAO.md
â”‚
â””â”€ END: 90% project complete âœ…
```

---

## â±ï¸ Timeline Estimado

| Fase | DuraÃ§Ã£o | Total |
|------|---------|-------|
| **CDC Setup + Test** | 30 min | 30 min |
| **RLAC Setup + Test** | 25 min | 55 min |
| **BI Setup + Test** | 25 min | 80 min |
| **Documentation** | 15 min | 95 min |
| **Final validation** | 5 min | 100 min |

**Total:** ~1.5-2 horas (com possÃ­veis ajustes)

---

## ğŸ“ Learning Objectives

Ao final desta iteraÃ§Ã£o, vocÃª entenderÃ¡:

- âœ… Como implementar CDC em Apache Iceberg
- âœ… Como controlar acesso a nÃ­vel de linha
- âœ… Como integrar DataLake com ferramentas de BI
- âœ… Como medir performance de queries distribuÃ­das
- âœ… Como deployar sistema em produÃ§Ã£o

---

## ğŸš¦ Status Dashboard

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ITERATION 5 STATUS - 7 DEC 2025        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  CDC Implementation        â³ PLANNED   â”‚
â”‚  RLAC Implementation       â³ PLANNED   â”‚
â”‚  BI Integration            â³ PLANNED   â”‚
â”‚  Documentation             â³ PLANNED   â”‚
â”‚                                         â”‚
â”‚  Overall Progress:        0% â–¯â–¯â–¯â–¯â–¯â–¯â–¯â–¯  â”‚
â”‚  ETA Completion:          ~2 hours      â”‚
â”‚  Target Project %:        90%           â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ PrÃ³ximas AÃ§Ãµes

1. **Agora:** Confirmar estrutura de IteraÃ§Ã£o 5
2. **Depois:** Criar `test_cdc_pipeline.py`
3. **Depois:** Criar `test_rlac_implementation.py`
4. **Depois:** Criar `test_bi_integration.py`
5. **Depois:** Executar todos os testes
6. **Depois:** Documentar resultados
7. **Final:** Marcar IteraÃ§Ã£o 5 como 100% âœ…

---

**Documento Criado:** 7 de dezembro de 2025  
**VersÃ£o:** 1.0  
**Status:** Ready for Implementation ğŸš€
