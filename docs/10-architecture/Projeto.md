# üìò **Arquitetura da Plataforma de Dados GTI (Docker Edition)**

### **Vers√£o 2.0 ‚Äì Stack Unificada em Docker**

---

# üìë **√çNDICE**

1.  [Vis√£o Geral](#1-vis√£o-geral-do-projeto)
2.  [Arquitetura T√©cnica](#2-arquitetura-t√©cnica)
3.  [Componentes do Ecossistema](#3-componentes-do-ecossistema)
4.  [Fluxos de Dados e Mudan√ßa](#4-fluxos)
5.  [Especifica√ß√µes e Vers√µes](#5-especifica√ß√µes-t√©cnicas)

---

## **1. Vis√£o Geral do Projeto**

### **1.1 Objetivo**
Fornecer uma plataforma de dados moderna, aut√¥noma e resiliente, baseada no conceito de **Lakehouse**. A infraestrutura √© agn√≥stica a provedor de nuvem, rodando 100% on-premise (ou em qualquer VM Linux) atrav√©s de cont√™ineres Docker orquestrados via Docker Compose.

### **1.2 Paradigma Lakehouse**
A plataforma combina a flexibilidade de um Data Lake com a gest√£o de dados de um Data Warehouse:
*   **Armazenamento Barato:** Object Storage (MinIO)
*   **Transacionalidade:** Apache Iceberg (ACID, Time Travel)
*   **Processamento Esc√°vel:** Apache Spark
*   **Consulta SQL R√°pida:** Trino

---

## **2. Arquitetura T√©cnica**

A arquitetura migrou de m√∫ltiplos containers LXC isolados para um **Stack Docker Unificado**.

### **2.1 Topologia L√≥gica (Docker Network)**
Todos os servi√ßos comunicam-se atrav√©s de uma rede bridge interna (`docker_datalake-net`), utilizando resolu√ß√£o de nomes de servi√ßo (DNS do Docker).

```mermaid
graph TD
    subgraph "Docker Host"
        subgraph "Network: datalake-net"
            K[Kafka Cluster] --> S[Spark Cluster]
            S --> M[MinIO (S3)]
            H[Hive Metastore] -.-> M
            S -.-> H
            T[Trino] --> M
            T --> H
            B[Superset] --> T
            G[Gitea]
        end
        Ext[Datagen] -.-> K
    end
```

### **2.2 Armazenamento Persistente**
Volumes Docker nomeados garantem a persist√™ncia dos dados cr√≠ticos:
*   `minio_data`: Dados brutos e tabelas Iceberg.
*   `mariadb_data`: Metadados do Hive.
*   `postgres_data`: Metadados do Superset.
*   `gitea_data` / `gitea_db`: Reposit√≥rios Git.
*   `kafka_data` / `zookeeper_data`: Logs de eventos.

---

## **3. Componentes do Ecossistema**

### **Infraestrutura Core**
1.  **MinIO (S3)**: O "disco r√≠gido" do Lakehouse. Armazena parquets, metadados Iceberg e checkpoints.
2.  **Hive Metastore**: O cat√°logo central. Mapeia onde est√£o as tabelas Iceberg para que Spark e Trino possam encontr√°-las. Backend: MariaDB.
3.  **Apache Spark (Master/Worker)**: O "motor" de processamento. Realiza ingest√£o (Streaming) e transforma√ß√£o (Batch) pesada.
4.  **Trino**: O motor de consulta SQL. Permite que analistas consultem o Lakehouse via SQL padr√£o com alta performance.
5.  **Kafka Stack**:
    *   **Zookeeper & Broker**: Barramento de eventos em tempo real.
    *   **Kafka Connect**: Ingest√£o de fontes externas (bancos, arquivos) para t√≥picos.
    *   **Kafka UI**: Interface de gest√£o.

### **Aplica√ß√µes e Ferramentas**
6.  **Apache Superset**: Visualiza√ß√£o de dados (Dashboards) conectado ao Trino.
7.  **Gitea**: Servidor Git self-hosted para versionamento de c√≥digo, DAGs e configura√ß√µes (GitOps).

---

## **4. Fluxos**

### **4.1 Fluxo de Dados (Pipeline Padr√£o)**
1.  **Ingest√£o**: Dados s√£o gerados (ex: Datagen) e enviados para o **Kafka**.
2.  **Processamento**: Jobs **Spark Streaming** leem do Kafka, aplicam regras de neg√≥cio e escrevem no **MinIO** em formato **Iceberg**.
3.  **Cat√°logo**: O **Hive Metastore** registra os novos snapshots das tabelas.
4.  **Consumo**: Usu√°rios usam o **Superset**, que envia SQL para o **Trino**, que l√™ os dados do **MinIO**.

### **4.2 Fluxo de GitOps**
1.  Desenvolvedor commita c√≥digo (Job Spark ou SQL) no **Gitea**.
2.  Pipeline (ou Deployer manual) atualiza o ambiente produtivo.
3.  O c√≥digo versionado √© a √∫nica fonte da verdade.

---

## **5. Especifica√ß√µes T√©cnicas**

### **5.1 Vers√µes (Stack Lock)**
| Componente | Vers√£o | Fun√ß√£o |
| :--- | :--- | :--- |
| **Spark** | 3.5.4 | Processamento |
| **Iceberg** | 1.10.0 | Configura√ß√£o via JARs |
| **Trino** | Latest | Query Engine |
| **MinIO** | Latest | Object Storage |
| **Kafka** | 7.5.0 (CP) | Streaming |
| **Superset** | Latest | BI |
| **Gitea** | 1.24.2 | Versionamento |

### **5.2 Portas de Servi√ßo (Host)**
| Servi√ßo | Porta Interna | Porta Exposta (Host) |
| :--- | :--- | :--- |
| **Gitea** | 3000 | 3000 |
| **Superset** | 8088 | 8088 |
| **Trino** | 8080 | 8081 |
| **Spark Master** | 8080 | 8085 |
| **MinIO Console**| 9001 | 9001 |
| **MinIO API** | 9000 | 9000 |
| **Kafka UI** | 8080 | 8090 |
| **Kafka Broker** | 9092 | 29092 (Ext) |

### **5.3 Requisitos de Hardware (M√≠nimo Recomendado)**
Para rodar o stack completo via Docker:
*   **CPU**: 4 vCPUs ou mais.
*   **RAM**: 16 GB (Recomendado 32 GB para cargas de trabalho reais).
*   **Disco**: 50 GB+ SSD.

---

**Documenta√ß√£o mantida pela Equipe de Dados GTI.**
