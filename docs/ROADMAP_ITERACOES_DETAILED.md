# Roadmap: 5 IteraÃ§Ãµes para DataLake Iceberg Production-Ready

**Timeline:** 10 semanas | **ComeÃ§ou:** 2025-12-07 | **Meta:** 2026-02-09

---

## ğŸ“Š Resumo Executivo

| Iter. | Nome | Foco | Status | Semanas |
|-------|------|------|--------|---------|
| 1 | **Baseline** | ValidaÃ§Ã£o + Performance | âœ… COMPLETO | 1-2 |
| 2 | **Time Travel & UPSERT** | Versionamento + Updates | ğŸš€ IN PROGRESS | 3-4 |
| 3 | **Compaction & Maintenance** | OtimizaÃ§Ã£o | â³ PLANNED | 5-6 |
| 4 | **Production Hardening** | Security + HA | â³ PLANNED | 7-8 |
| 5 | **Advanced Features** | CDC + RBAC | â³ PLANNED | 9-10 |

---

## ğŸ”„ Iteration 1: Baseline Performance & Validation

**Status:** âœ… **COMPLETO** (2025-12-07)

### Deliverables
- âœ… Data generator: 50K records em 1.91s
- âœ… 10 benchmark queries com metrics
- âœ… Partition pruning validation
- âœ… OutOfMemory error resolved (2GB executor)
- âœ… ITERATION_1_RESULTS.md + benchmark_results.json

### Key Metrics
| MÃ©trica | Valor |
|---------|-------|
| Tempo mÃ©dio query | 1.599s |
| Query mais rÃ¡pida | 0.343s (partition filter) |
| CompressÃ£o | 383KB (50K records) |
| Taxa sucesso | 100% |

### Handoff para Iter. 2
```
âœ… Tabela criada: hadoop_prod.default.vendas_small
âœ… Snapshots: 2 (v1=v2.metadata.json, current)
âœ… Dados particionados por (year=2025, month=1-12)
âœ… Ready para Time Travel tests
```

---

## ğŸ• Iteration 2: Time Travel & Schema Evolution

**Timeline:** 2025-12-21 atÃ© 2026-01-04

### 2.1 Time Travel (Snapshots & Versioning)

#### Tasks
- [ ] **T2.1.1:** Criar tabela `time_travel_test` com snapshots
  - Setup: 10 records V1
  - Insert: +10 records V2
  - Read: V1, V2, Current
  
- [ ] **T2.1.2:** Validate `SELECT ... VERSION AS OF <snapshot_id>`
  - Comparar V1 (10 rows) vs V2 (20 rows)
  - Comparar V2 vs Current
  - Benchmark: time-travel query vs. full scan

- [ ] **T2.1.3:** Test snapshot retention
  - `SELECT * FROM table.snapshots` â†’ listar todas
  - Verificar metadatas em S3
  - `EXPIRE_SNAPSHOTS` behavior

#### Arquivo
`test_time_travel.py` - 150 linhas
- Setup table com 2 batches
- Insertar 10 + 10 records
- Query via `VERSION AS OF`
- Compare snapshots

#### Validation
```sql
-- Snapshot ID V1
SELECT snapshot_id, committed_at 
FROM vendas_small.snapshots 
ORDER BY committed_at DESC LIMIT 1;

-- Query na V1
SELECT COUNT(*) FROM vendas_small VERSION AS OF 1948373279699042674;
-- Expected: 10
```

### 2.2 UPSERT via MERGE INTO

#### Tasks
- [ ] **T2.2.1:** Criar tabela `inventory` com dados iniciais (5 produtos)
  - Schema: product_id (PK), quantity, price, updated_at
  - Partition: (year, month)

- [ ] **T2.2.2:** Preparar `inventory_updates` com 5 records
  - 3 updates (quantity/price change)
  - 2 inserts (novos produtos)

- [ ] **T2.2.3:** Executar `MERGE INTO ... WHEN MATCHED ... WHEN NOT MATCHED`
  - Validar UPDATE de 3 registros
  - Validar INSERT de 2 registros
  - Total esperado: 7 records

#### Arquivo
`test_merge_into.py` - 200 linhas
- Create table + create temp table
- Initial load 5 products
- Prepare 3 updates + 2 inserts
- MERGE operation
- Validate: 7 records total

#### Validation
```sql
-- Antes: 5 records
SELECT COUNT(*) FROM inventory;

-- Merge
MERGE INTO inventory t USING inventory_updates s ON ...

-- Depois: 7 records
SELECT COUNT(*) FROM inventory;
-- Expected: 7

-- Verificar updates
SELECT product_id, quantity FROM inventory WHERE product_id IN ('PROD_001', 'PROD_002');
-- PROD_001: 50 (atualizado de 100)
```

### 2.3 Schema Evolution

#### Tasks
- [ ] **T2.3.1:** ADD COLUMN `category` STRING
  - Alter table vendas_small
  - Verificar que dados antigos nÃ£o tÃªm categoria

- [ ] **T2.3.2:** INSERT com nova coluna
  - Adicionar 10 records com category=NEW

- [ ] **T2.3.3:** Query vendas_small com/sem category
  - Validar que NULLs aparecem para v1 data
  - Validar que nova coluna aparece

#### Arquivo
`test_schema_evolution.py` - 150 linhas

### Deliverables
```
âœ… test_time_travel.py
âœ… test_merge_into.py
âœ… test_schema_evolution.py
âœ… ITERATION_2_RESULTS.md
âœ… Snapshots metadata validation
```

### Success Criteria
- âœ… `VERSION AS OF` queries retornam dados corretos
- âœ… MERGE INTO insere + atualiza
- âœ… Schema evolution sem perder dados antigos
- âœ… 0 errors durante operaÃ§Ãµes

---

## ğŸ§¹ Iteration 3: Compaction & Optimization

**Timeline:** 2026-01-05 atÃ© 2026-01-18

### 3.1 Data Compaction

#### Tasks
- [ ] **T3.1.1:** Baseline: medir fragmentaÃ§Ã£o
  - `SELECT COUNT(data_files) FROM vendas_small.files`
  - Mostrar tamanho total vs. count de files

- [ ] **T3.1.2:** REWRITE DATA FILES
  - `ALTER TABLE vendas_small EXECUTE REWRITE DATA FILES`
  - Medir tempo de rewrite

- [ ] **T3.1.3:** Post-compaction metrics
  - Comparar files antes/depois
  - Comparar query performance

#### Arquivo
`test_compaction.py` - 180 linhas

### 3.2 Snapshot Lifecycle

#### Tasks
- [ ] **T3.2.1:** EXPIRE_SNAPSHOTS
  - Set retention: 7 days
  - Remover snapshots antigos

- [ ] **T3.2.2:** REMOVE_ORPHAN_FILES
  - Limpar arquivos Ã³rfÃ£os em S3
  - Validar que nÃ£o afeta queries

- [ ] **T3.2.3:** Monitorar cleanup
  - Logging de expired snapshots
  - Disk space recovery

#### Arquivo
`test_snapshot_lifecycle.py` - 150 linhas

### 3.3 Monitoring & Stats

#### Tasks
- [ ] **T3.3.1:** Collect table statistics
  - File count, row count, size
  - Partition distribution

- [ ] **T3.3.2:** Query analyzer
  - Logging: query time, partition pruning efficiency
  - Identify slow queries

#### Arquivo
`test_monitoring.py` - 200 linhas

### Deliverables
```
âœ… test_compaction.py
âœ… test_snapshot_lifecycle.py
âœ… test_monitoring.py
âœ… ITERATION_3_RESULTS.md
âœ… Performance comparison report
```

### Success Criteria
- âœ… Compaction reduz file count em 50%+
- âœ… Query performance igual/melhor
- âœ… Orphan files removidos
- âœ… Snapshots expirados com sucesso

---

## ğŸ” Iteration 4: Production Hardening

**Timeline:** 2026-01-19 atÃ© 2026-02-01

### 4.1 Security & Access Control

#### Tasks
- [ ] **T4.1.1:** IAM policies para Spark/Iceberg
  - S3 bucket policies
  - MinIO access logs

- [ ] **T4.1.2:** Credential rotation
  - Test changing spark_user password
  - Verify Spark still connects

- [ ] **T4.1.3:** Encryption at rest
  - S3A SSE-S3 setup
  - Verify MinIO encrypts data

### 4.2 High Availability & DR

#### Tasks
- [ ] **T4.2.1:** Backup strategy
  - S3 backup bucket replication
  - Metadata backup frequency

- [ ] **T4.2.2:** Restore procedure
  - Simular restore from backup
  - Verify data integrity

- [ ] **T4.2.3:** Disaster recovery test
  - "Destroy" e rebuild table
  - Validate restore time

### 4.3 Monitoring & Alerting

#### Tasks
- [ ] **T4.3.1:** Prometheus metrics
  - Spark metrics export
  - MinIO S3 metrics

- [ ] **T4.3.2:** Grafana dashboards
  - DataLake health dashboard
  - Query performance trends

- [ ] **T4.3.3:** Alerting rules
  - OOM > threshold
  - Query time > SLA
  - Snapshot growth

### Deliverables
```
âœ… Security configuration guide
âœ… Backup/restore procedure
âœ… DR runbook
âœ… Monitoring setup
âœ… ITERATION_4_RESULTS.md
```

### Success Criteria
- âœ… Backup/restore em < 1 hora
- âœ… 0 security vulnerabilities
- âœ… Alertas funcionando
- âœ… RTO = 30 min, RPO = 5 min

---

## ğŸš€ Iteration 5: Advanced Features

**Timeline:** 2026-02-02 atÃ© 2026-02-09

### 5.1 Change Data Capture (CDC)

#### Tasks
- [ ] **T5.1.1:** CDC setup com Iceberg + Flink
  - Capture inserts/updates/deletes
  - Stream to Kafka

- [ ] **T5.1.2:** CDC consumer
  - Read from Kafka
  - Apply to downstream system

- [ ] **T5.1.3:** CDC metrics
  - Latency measurement
  - Throughput testing

### 5.2 Row-Level Access Control (RLAC)

#### Tasks
- [ ] **T5.2.1:** Row filtering via SQL
  - User A sees only region=North
  - User B sees only region=South

- [ ] **T5.2.2:** Column-level masking
  - Price column masked for analysts
  - Email column redacted for non-admins

- [ ] **T5.2.3:** Audit logging
  - Log all access attempts
  - Track who accessed what

### 5.3 BI Tool Integration

#### Tasks
- [ ] **T5.3.1:** Tableau connection
  - Direct SQL query
  - Performance testing

- [ ] **T5.3.2:** Power BI integration
  - Via Spark connector
  - Dashboard creation

- [ ] **T5.3.3:** Metadata catalog
  - Column descriptions
  - Lineage tracking

### Deliverables
```
âœ… CDC pipeline setup
âœ… RLAC implementation
âœ… BI integration guide
âœ… ITERATION_5_RESULTS.md
âœ… Production readiness checklist
```

### Success Criteria
- âœ… CDC latency < 5 minutes
- âœ… RLAC nÃ£o impacta performance
- âœ… BI tools retornam queries em < 30s
- âœ… 100% uptime SLA

---

## ğŸ“‹ Cross-Iteration Concerns

### Monitoring (all iterations)
- Query execution time
- Memory utilization
- Storage growth
- Snapshot count

### Testing (all iterations)
- Unit tests para cada feature
- Integration tests
- Load tests (100K, 500K, 1M records)
- Regression tests

### Documentation (all iterations)
- Code comments
- Runbooks
- API documentation
- Troubleshooting guides

---

## ğŸ¯ Success Metrics

### Iter. 1
- âœ… Baseline estabelecido
- âœ… 50K records em 1.91s

### Iter. 2
- âœ… Time Travel validado
- âœ… MERGE INTO funcional
- âœ… Schema evolution testado

### Iter. 3
- âœ… Compaction reduz files 50%
- âœ… Query performance igual/melhor
- âœ… Cleanup automÃ¡tico

### Iter. 4
- âœ… Security hardened
- âœ… Backup/restore < 1h
- âœ… Monitoring + alertas

### Iter. 5
- âœ… CDC < 5 min latency
- âœ… RLAC implementado
- âœ… BI integrado

### **Final Status:** ğŸ† **PRODUCTION READY**

---

## ğŸ“… Timeline Visual

```
Semana 1-2:   Iteration 1 [=====âœ…=====]
Semana 3-4:   Iteration 2         [=====ğŸš€====]
Semana 5-6:   Iteration 3                [====â³====]
Semana 7-8:   Iteration 4                        [===â³===]
Semana 9-10:  Iteration 5                              [==â³==]
```

---

## ğŸ”— File Dependencies

```
ITERATION_1_RESULTS.md
â”œâ”€â”€ benchmark_results.json
â”œâ”€â”€ test_simple_data_gen.py
â””â”€â”€ test_simple_benchmark.py

ROADMAP_ITERACOES.md (este documento)
â”œâ”€â”€ ITERATION_2_TASKS.md
â”‚   â”œâ”€â”€ test_time_travel.py
â”‚   â”œâ”€â”€ test_merge_into.py
â”‚   â””â”€â”€ test_schema_evolution.py
â”œâ”€â”€ ITERATION_3_TASKS.md
â”‚   â”œâ”€â”€ test_compaction.py
â”‚   â”œâ”€â”€ test_snapshot_lifecycle.py
â”‚   â””â”€â”€ test_monitoring.py
â”œâ”€â”€ ITERATION_4_TASKS.md
â”‚   â”œâ”€â”€ security_hardening.md
â”‚   â”œâ”€â”€ dr_procedure.md
â”‚   â””â”€â”€ monitoring_setup.md
â””â”€â”€ ITERATION_5_TASKS.md
    â”œâ”€â”€ cdc_pipeline.md
    â”œâ”€â”€ rlac_implementation.md
    â””â”€â”€ bi_integration.md
```

---

## ğŸ“ Contact & Support

- **Lead:** DataLake Engineering Team
- **Repo:** https://github.com/gti-next/datalake-iceberg
- **Slack:** #datalake-engineering
- **Meetings:** Weekly sync (Tuesdays 10:00 AM BRT)

---

**Documento atualizado:** 2025-12-07 00:11:31 UTC
**Status Geral:** Iteration 1 âœ… | Iteration 2 ğŸš€ | Production ğŸ†
**PrÃ³xima Review:** 2025-12-21 (Iter. 2 P1 checkpoint)
